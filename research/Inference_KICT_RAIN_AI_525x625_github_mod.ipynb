{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf1f694-030f-4bb4-b281-59659901eabe",
   "metadata": {
    "id": "cdf1f694-030f-4bb4-b281-59659901eabe"
   },
   "source": [
    "#-------------------------------------------------------------------------#\n",
    "#           KICT-RAIN-AI using Grided Rainfall data                       #\n",
    "#Ver.1 revised by Seong-Sim Yoon  Oct.2023                                #\n",
    "#Copyright : KOREA INSTITUTE of CIVIL ENGINEERING and BUILDING TECHNOLOGY #\n",
    "#-------------------------------------------------------------------------#\n",
    "#Input : ASCII File(radar rainfall)\n",
    "#Input Data Coordinate  : EPSG5186\n",
    "#Resoultion : 1km, every 10min\n",
    "#units : mm/hr\n",
    "#Ouput : ASCII File(grid rainfall)\n",
    "# KICT-RAIN-AI PROCESS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "w8UPNplJL7w0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8UPNplJL7w0",
    "outputId": "8229bc51-42d2-436e-b409-fc5616610de8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=14Cz1yDCtrbI3KoHlU4GiNXwyCVKS-clX\n",
      "To: /content/model-best_fcst_10min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 68.7MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=11FNN6ekYG5gpmONQCozPQYc2FH-zLNlM\n",
      "To: /content/model-best_fcst_20min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 60.5MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1zsQjoh_nqqEa-9fz91P24xx1FoyDKB_G\n",
      "To: /content/model-best_fcst_30min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 80.9MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1FvcROg3Sal2NBAKXG3qRoPsVyIGfph5q\n",
      "To: /content/model-best_fcst_40min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 83.1MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1pixZOvE87vFUHLDdei-yvCisBuUJuthM\n",
      "To: /content/model-best_fcst_50min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 61.1MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=13YWC2efMsKvbNpZ5L_daGkJ0Bpujezqc\n",
      "To: /content/model-best_fcst_60min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 77.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1MjzRQb1FWz0lKoaAGhiS23TvIjYncGB7\n",
      "To: /content/model-best_fcst_70min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 81.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1JUrlUDe1EYvoOkQj1jKRerLu5a4F3-as\n",
      "To: /content/model-best_fcst_80min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 75.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1xzxRDR_YZWz-2oiPEpjTUKQAUHe4-PHj\n",
      "To: /content/model-best_fcst_90min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 93.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1HlPbS1hlFruMS9uNAjUp20WmHtMoiSwR\n",
      "To: /content/model-best_fcst_100min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 57.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1DK2YSAKqDOWBhlH9BkfD0oJX2yzhnG7Z\n",
      "To: /content/model-best_fcst_110min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 74.9MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1t4KnIHIn3mWChzpJh4v20CB9lhsF84v6\n",
      "To: /content/model-best_fcst_120min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 50.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=14HPeJjzE50ziTQOWs4HhwiK_ftHYIeq3\n",
      "To: /content/model-best_fcst_130min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 60.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Ep721RZV3CpFy23se47jG8m9qQiygxAb\n",
      "To: /content/model-best_fcst_140min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 72.5MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1pCeW1umNiudMD7yWDHF-hfgb5sXW3YKC\n",
      "To: /content/model-best_fcst_150min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 63.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1GxzveX6pQeqqoVuvdj2qUeURJOgDTffp\n",
      "To: /content/model-best_fcst_160min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 64.5MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1h33EX7ZUlw-OJzgGUHKC6xYQkhJsoUWW\n",
      "To: /content/model-best_fcst_170min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 47.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1oHvK5CqXKVbbVW5eQtfyzoAp_RPaouZC\n",
      "To: /content/model-best_fcst_180min.tflite\n",
      "100% 31.1M/31.1M [00:00<00:00, 65.0MB/s]\n",
      "usage: gdown [-h] [-V] [-O OUTPUT] [-q] [--fuzzy] [--id] [--proxy PROXY] [--speed SPEED]\n",
      "             [--no-cookies] [--no-check-certificate] [--continue] [--folder] [--remaining-ok]\n",
      "             url_or_id\n",
      "gdown: error: unrecognized arguments: QPF-REC model for 10-180min\n",
      "mkdir: cannot create directory ‘/content/models’: File exists\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# 구글드라이브 사전학습된 모델(.tflite) 불러오기\n",
    "# 코랩 가상 드라이브에 저장\n",
    "!gdown https://drive.google.com/uc?id=14Cz1yDCtrbI3KoHlU4GiNXwyCVKS-clX #pretrained QPF model for 10min\n",
    "!gdown https://drive.google.com/uc?id=11FNN6ekYG5gpmONQCozPQYc2FH-zLNlM #pretrained QPF model for 20min\n",
    "!gdown https://drive.google.com/uc?id=1zsQjoh_nqqEa-9fz91P24xx1FoyDKB_G #pretrained QPF model for 30min\n",
    "!gdown https://drive.google.com/uc?id=1FvcROg3Sal2NBAKXG3qRoPsVyIGfph5q #pretrained QPF model for 40min\n",
    "!gdown https://drive.google.com/uc?id=1pixZOvE87vFUHLDdei-yvCisBuUJuthM #pretrained QPF model for 50min\n",
    "!gdown https://drive.google.com/uc?id=13YWC2efMsKvbNpZ5L_daGkJ0Bpujezqc #pretrained QPF model for 60min\n",
    "!gdown https://drive.google.com/uc?id=1MjzRQb1FWz0lKoaAGhiS23TvIjYncGB7 #pretrained QPF model for 70min\n",
    "!gdown https://drive.google.com/uc?id=1JUrlUDe1EYvoOkQj1jKRerLu5a4F3-as #pretrained QPF model for 80min\n",
    "!gdown https://drive.google.com/uc?id=1xzxRDR_YZWz-2oiPEpjTUKQAUHe4-PHj #pretrained QPF model for 90min\n",
    "!gdown https://drive.google.com/uc?id=1HlPbS1hlFruMS9uNAjUp20WmHtMoiSwR #pretrained QPF model for 100min\n",
    "!gdown https://drive.google.com/uc?id=1DK2YSAKqDOWBhlH9BkfD0oJX2yzhnG7Z #pretrained QPF model for 110min\n",
    "!gdown https://drive.google.com/uc?id=1t4KnIHIn3mWChzpJh4v20CB9lhsF84v6 #pretrained QPF model for 120min\n",
    "!gdown https://drive.google.com/uc?id=14HPeJjzE50ziTQOWs4HhwiK_ftHYIeq3 #pretrained QPF model for 130min\n",
    "!gdown https://drive.google.com/uc?id=1Ep721RZV3CpFy23se47jG8m9qQiygxAb #pretrained QPF model for 140min\n",
    "!gdown https://drive.google.com/uc?id=1pCeW1umNiudMD7yWDHF-hfgb5sXW3YKC #pretrained QPF model for 150min\n",
    "!gdown https://drive.google.com/uc?id=1GxzveX6pQeqqoVuvdj2qUeURJOgDTffp #pretrained QPF model for 160min\n",
    "!gdown https://drive.google.com/uc?id=1h33EX7ZUlw-OJzgGUHKC6xYQkhJsoUWW #pretrained QPF model for 170min\n",
    "!gdown https://drive.google.com/uc?id=1oHvK5CqXKVbbVW5eQtfyzoAp_RPaouZC #pretrained QPF model for 180min\n",
    "#!gdown https://drive.google.com/uc?id=1F94iWjoUYzWXfvP1-sDuYlOfSdNJFPN7 #pretrained QPF-REC model for 10-180min\n",
    "!gdowm https://drive.google.com/uc?id=1CxbdCAe8kRBqGQNEXVd-dHkKL8ISi_dq  #pretrained QPF-REC model for 10-180min (tflite)\n",
    "!mkdir /content/models\n",
    "!mv /content/*.tflite /content/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "iDoGxFZfTG2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDoGxFZfTG2b",
    "outputId": "c7b3b9ed-0f55-44a4-cd7e-9a3c5fe7794d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1b2Thq96CqzYzaT34w1OGZ-vPV9-q3XwU\n",
      "To: /content/INPUT_ASC_20220808.zip\n",
      "100% 8.51M/8.51M [00:00<00:00, 23.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Input data 불러오기\n",
    "# 코랩 가상 드라이브에 저장\n",
    "!gdown https://drive.google.com/uc?id=1b2Thq96CqzYzaT34w1OGZ-vPV9-q3XwU #INPUT_ASC_20220808.zip 파일\n",
    "!unzip -qq '/content/INPUT_ASC_20220808.zip' -d '/content/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98371e80-0af2-490e-bd9a-8a51d62e5edb",
   "metadata": {
    "id": "98371e80-0af2-490e-bd9a-8a51d62e5edb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 11:19:13.575845: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import gc\n",
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "import datetime\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.losses import mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f39d8c5-24f1-45a8-b7e0-a2523e5234a0",
   "metadata": {
    "id": "7f39d8c5-24f1-45a8-b7e0-a2523e5234a0"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "# Metrics\n",
    "def mae255(y_true, y_pred):\n",
    "    return 255 * mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "\n",
    "# f1 score 계산\n",
    "def Rain(array):\n",
    "    R = array * 255.0\n",
    "    return R\n",
    "\n",
    "\n",
    "def CSI_m(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    remove_NAs = y_true > 0\n",
    "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
    "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
    "    right = np.sum(y_true * y_pred == 1)\n",
    "    # print(right,np.sum(y_pred),np.sum(y_true),right)\n",
    "    CSI = right / (np.sum(y_pred) + np.sum(y_true) - right + 1e-07)\n",
    "    return CSI\n",
    "\n",
    "\n",
    "def CSI_custom(y_true, y_pred):\n",
    "    score = tf.py_function(\n",
    "        func=CSI_m, inp=[y_true, y_pred], Tout=tf.float32, name=\"CSI_custom\"\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "\n",
    "def mae_custom(y_true, y_pred):\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = tf.convert_to_tensor(y_true)\n",
    "    y_true = Rain(y_true)\n",
    "    y_pred = Rain(y_pred)\n",
    "    thr1 = K.greater(y_true, 0.1)\n",
    "    loss1 = K.mean(K.abs(y_true[thr1] - y_pred[thr1]))\n",
    "    arr = [loss1]\n",
    "    value_not_nan = tf.dtypes.cast(\n",
    "        tf.math.logical_not(tf.math.is_nan(arr)), dtype=tf.float32\n",
    "    )\n",
    "    loss0 = tf.math.multiply_no_nan(arr, value_not_nan)\n",
    "    loss = tf.convert_to_tensor(K.sum(loss0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901a2417-81cf-4ffe-8161-1bf4759680da",
   "metadata": {
    "id": "901a2417-81cf-4ffe-8161-1bf4759680da"
   },
   "source": [
    "#특정시점 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5312ef05-1d68-4647-8a14-31d59a479666",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5312ef05-1d68-4647-8a14-31d59a479666",
    "outputId": "10983a78-bc62-4cb8-b819-a789be4685b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/content/QPF’: No such file or directory\n",
      "2208082200\n"
     ]
    }
   ],
   "source": [
    "# 예측 시점 입력\n",
    "!mkdir /content/QPF\n",
    "date_nm = \"202208082200\"  # 날짜 수정\n",
    "run_date = date_nm[2:12]\n",
    "print(run_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2de5a3d-1ae4-4d76-b0e6-f395c93b4bdd",
   "metadata": {
    "id": "a2de5a3d-1ae4-4d76-b0e6-f395c93b4bdd"
   },
   "outputs": [],
   "source": [
    "# READ INPUT DATA (PAST 4 data)\n",
    "def read_ASC(timestamp):\n",
    "    #    print(timestams)\n",
    "    YY = timestamp[0:2]\n",
    "    MM = timestamp[2:4]\n",
    "    DD = timestamp[4:6]\n",
    "    HH = timestamp[6:8]\n",
    "    MN = timestamp[8:10]\n",
    "    RDR_time = timestamp[0:10]\n",
    "    YYYY = \"20\" + YY\n",
    "    print(RDR_time)\n",
    "    path = \"/content/data\"\n",
    "    filename = path + \"/RDR_CMP_HSP_PUB_20\" + RDR_time + \"-525x625-1km.asc\"\n",
    "    data = np.zeros([625, 525], np.float32)  # ASCII랑배열 반대\n",
    "    data = np.loadtxt(filename, skiprows=6)\n",
    "    data[data < 0] = 0.0\n",
    "    attr = datetime.datetime(int(YYYY), int(MM), int(DD), int(HH), int(MN))\n",
    "    return data, attr\n",
    "\n",
    "\n",
    "def qpe_data(filetime):\n",
    "    YY = filetime[0:2]\n",
    "    MM = filetime[2:4]\n",
    "    DD = filetime[4:6]\n",
    "    HH = filetime[6:8]\n",
    "    MN = filetime[8:10]\n",
    "    YYYY = \"20\" + YY\n",
    "    latest_datetime = datetime.datetime(int(YYYY), int(MM), int(DD), int(HH), int(MN))\n",
    "    # print(latest_datetime)\n",
    "    list_for_qpf = [\n",
    "        ts.strftime(\"%y%m%d%H%M\")\n",
    "        for ts in [\n",
    "            latest_datetime - datetime.timedelta(minutes=t) for t in [30, 20, 10, 0]\n",
    "        ]\n",
    "    ]\n",
    "    input_scans = np.array([read_ASC(ts)[0] for ts in list_for_qpf])\n",
    "    qpe_scans = np.concatenate([input_scans], axis=0)\n",
    "    print(qpe_scans.shape)\n",
    "    return qpe_scans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ab7548-ee98-485f-aca7-896b84ab5cf8",
   "metadata": {
    "id": "d6ab7548-ee98-485f-aca7-896b84ab5cf8"
   },
   "source": [
    "# KICT-RAIN-AI_ver1\n",
    "기법: 재귀적 학습전략이 포함된 U-net 기반의 모델로, inference에서 재귀적 예측을 사용하지 않더라도 4개의 입력 강우장으로  18개(10분~180분) 예측강우장 생성<br/>\n",
    "사전학습된 예측강우 모델: model-best_rec_180min_f.tflite <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc578e7c-d6ec-47b5-bd9e-cb0f2d77ab00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc578e7c-d6ec-47b5-bd9e-cb0f2d77ab00",
    "outputId": "c1622269-442e-458f-b335-5f1257dbdc28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2208082130\n",
      "2208082140\n",
      "2208082150\n",
      "2208082200\n",
      "(4, 625, 525)\n",
      "1 (4, 625, 525)\n",
      "2 (625, 525, 4)\n",
      "3 (18, 640, 544)\n",
      "(18, 625, 525)\n"
     ]
    }
   ],
   "source": [
    "# 재귀적 학습 기반 강우예측 모델을 이용한 예측강우 생산\n",
    "#!gdowm https://drive.google.com/uc?id=1CxbdCAe8kRBqGQNEXVd-dHkKL8ISi_dq  #pretrained QPF-REC model for 10-180min (tflite)\n",
    "#!mv /content/*.tflite /content/models\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.lite.python import interpreter as interpreter_wrapper\n",
    "\n",
    "\n",
    "def prediction_rec(feature):\n",
    "    pre_model = \"model-best_rec_180min_f.tflite\"\n",
    "    interpreter = interpreter_wrapper.Interpreter(model_path=pre_model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # 입력 텐서 정보 가져오기\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    # input_shape = input_details[0][\"shape\"]\n",
    "\n",
    "    # 입력 데이터 변환 및 설정\n",
    "    feature = np.array(feature / 255.0, dtype=np.float32)  # FLOAT64에서 FLOAT32로 변환\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], feature)\n",
    "    # 모델 실행\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # 출력 데이터 가져오기\n",
    "    pred = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    pred = np.squeeze(pred)\n",
    "    nwcst = np.transpose(pred, (2, 0, 1))\n",
    "    return nwcst\n",
    "\n",
    "\n",
    "def save_as_ascii_grid(data, output_file):\n",
    "    \"\"\"\n",
    "    2D NumPy array를 ASCII grid 파일로 저장하는 함수\n",
    "    :param data: 2D NumPy array (격자 자료)\n",
    "    :param output_file: 저장할 파일 경로 및 이름 (예: 'output.asc')\n",
    "    \"\"\"\n",
    "    # EPSG 5186 기준\n",
    "    nrows, ncols = data.shape\n",
    "    header = f\"ncols {ncols}\\n\"\n",
    "    header += f\"nrows {nrows}\\n\"\n",
    "    header += \"xllcorner -31000\\n\"\n",
    "    header += \"yllcorner 123000\\n\"\n",
    "    header += \"cellsize 1000.0\\n\"  # 셀 크기\n",
    "    header += \"NODATA_value -9999.0\\n\"  # 누락된 데이터를 나타내는 값\n",
    "\n",
    "    np.savetxt(output_file, data, fmt=\"%.2f\", header=header, comments=\"\", delimiter=\" \")\n",
    "\n",
    "\n",
    "# 데이터 준비하기\n",
    "# FROM ASC (KMA mm/hr)\n",
    "dataset0 = qpe_data(run_date)\n",
    "print(\"1\", dataset0.shape)\n",
    "dataset = np.transpose(dataset0, (1, 2, 0))\n",
    "print(\"2\", dataset.shape)\n",
    "dataset = np.pad(dataset, [(7, 8), (9, 10), (0, 0)], mode=\"constant\", constant_values=0)\n",
    "feature0 = dataset[:, :, :]\n",
    "feature = np.where(feature0 < 0.0, 0, feature0)\n",
    "feature = np.expand_dims(feature, axis=0)\n",
    "nwcst = prediction_rec(feature)\n",
    "nwcst = nwcst * 255\n",
    "print(\"3\", nwcst.shape)\n",
    "# 매 예측시점 자료를 ASCII GRID 형식으로 저장(EPSG518 기준)\n",
    "for j in range(10, 190, 10):\n",
    "    output_file_path = \"/content/QPF/QPF_REC_\" + date_nm + \"-\" + str(j) + \".asc\"\n",
    "    k = int(j / 10 - 1)\n",
    "    qpf_np = nwcst[k, 7:632, 9:534]\n",
    "    save_as_ascii_grid(qpf_np, output_file_path)\n",
    "qpf_all = nwcst[:, 7:632, 9:534]\n",
    "print(qpf_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72d0a5-9f55-4205-84d1-546b8c50b85b",
   "metadata": {
    "id": "da72d0a5-9f55-4205-84d1-546b8c50b85b"
   },
   "source": [
    "# KICT-RAIN-AI_ver2\n",
    "기법: 매 선행 예측시점별 U-net을 최적화, 1개의 모델이 1개의 예측강우장 생성<br/>\n",
    "사전학습된 예측강우 모델: model-best_fcst_10min.h5~model-best_fcst_180min.h5, 18개<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "Mg3ITGz6Madf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mg3ITGz6Madf",
    "outputId": "01732264-62d3-49dd-cbdc-a55cfb9c3326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/content/QPF’: File exists\n",
      "2208082130\n",
      "2208082140\n",
      "2208082150\n",
      "2208082200\n",
      "(4, 625, 525)\n",
      "(1, 640, 544, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.lite.python import interpreter as interpreter_wrapper\n",
    "\n",
    "\n",
    "def data_preprocessing(X):\n",
    "    # 0. Right shape for batch\n",
    "    X = X[np.newaxis, ::, ::, ::]\n",
    "    return X\n",
    "\n",
    "\n",
    "def data_postprocessing(nwcst):\n",
    "    # 0. Squeeze empty dimensions\n",
    "    nwcst = np.squeeze(np.array(nwcst))\n",
    "    nwcst = nwcst\n",
    "    nwcst = np.where(nwcst > 0, nwcst, 0)\n",
    "    nwcst = nwcst[7:632, 9:534]\n",
    "    return nwcst\n",
    "\n",
    "\n",
    "def prediction(model_instance, input_data):\n",
    "    input_data = data_preprocessing(input_data)\n",
    "    print(input_data.shape)\n",
    "    pred = model_instance.predict(input_data)\n",
    "    print(pred.shape)\n",
    "    nwcst = np.squeeze(pred)  # np.transpose() 대신 np.squeeze()를 사용하세요.\n",
    "    return nwcst\n",
    "\n",
    "\n",
    "def save_as_ascii_grid(data, output_file):\n",
    "    \"\"\"\n",
    "    2D NumPy array를 ASCII grid 파일로 저장하는 함수\n",
    "    :param data: 2D NumPy array (격자 자료)\n",
    "    :param output_file: 저장할 파일 경로 및 이름 (예: 'output.asc')\n",
    "    \"\"\"\n",
    "    # EPSG 5186 기준\n",
    "    nrows, ncols = data.shape\n",
    "    header = f\"ncols {ncols}\\n\"\n",
    "    header += f\"nrows {nrows}\\n\"\n",
    "    header += \"xllcorner -31000\\n\"\n",
    "    header += \"yllcorner 123000\\n\"\n",
    "    header += \"cellsize 1000.0\\n\"  # 셀 크기\n",
    "    header += \"NODATA_value -9999.0\\n\"  # 누락된 데이터를 나타내는 값\n",
    "\n",
    "    np.savetxt(output_file, data, fmt=\"%.2f\", header=header, comments=\"\", delimiter=\" \")\n",
    "\n",
    "\n",
    "def prediction_tflite(feature):\n",
    "    qpf_all_each = np.empty((625, 525, 0))\n",
    "    for j in range(10, 190, 10):\n",
    "        # 이전 코드에서 필요한 설정과 모델 로딩을 진행한 후\n",
    "        pre_model = f\"/content/models/model-best_fcst_{j}min.tflite\"\n",
    "        interpreter = interpreter_wrapper.Interpreter(model_path=pre_model)\n",
    "        interpreter.allocate_tensors()\n",
    "\n",
    "        # 입력 텐서 정보 가져오기\n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "        input_shape = input_details[0][\"shape\"]\n",
    "\n",
    "        # 입력 데이터 변환 및 설정\n",
    "        feature = np.array(\n",
    "            feature / 255.0, dtype=np.float32\n",
    "        )  # FLOAT64에서 FLOAT32로 변환\n",
    "        interpreter.set_tensor(input_details[0][\"index\"], feature)\n",
    "        # 모델 실행\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # 출력 데이터 가져오기\n",
    "        nwcst = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "        nwcst = data_postprocessing(nwcst) * 255.0\n",
    "        # 예측하기\n",
    "        qpf_np = nwcst\n",
    "\n",
    "        # 매 예측시점 자료를 ASCII GRID 형식으로 저장(EPSG518 기준)\n",
    "        output_file_path = \"/content/QPF/QPF_\" + date_nm + \"-\" + str(j) + \".asc\"\n",
    "        save_as_ascii_grid(qpf_np, output_file_path)\n",
    "        # 이미지 처리를 위한 3차원 배열 예측강우 생성\n",
    "        qpf_np = np.expand_dims(qpf_np, axis=-1)  # 차원을 늘리세요.\n",
    "        qpf_all_each = np.concatenate([qpf_all_each, qpf_np], axis=-1)\n",
    "    return qpf_np, qpf_all_each\n",
    "\n",
    "\n",
    "# RUN\n",
    "dataset0 = qpe_data(run_date)\n",
    "dataset = np.transpose(dataset0, (1, 2, 0))\n",
    "dataset = np.pad(dataset, [(7, 8), (9, 10), (0, 0)], mode=\"constant\", constant_values=0)\n",
    "feature0 = dataset[:, :, :]\n",
    "feature = np.where(feature0 < 0.0, 0, feature0)\n",
    "feature = data_preprocessing(feature)\n",
    "print(feature.shape)\n",
    "\n",
    "qpf_np, qpf_all_each = prediction_tflite(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e334ed8c-ab6c-4510-92cd-903eb7d0c048",
   "metadata": {
    "id": "e334ed8c-ab6c-4510-92cd-903eb7d0c048"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "UNET",
   "language": "python",
   "name": "unet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
